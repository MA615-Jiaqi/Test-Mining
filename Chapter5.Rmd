---
title: "Chapter5"
author: "Jiaqi Sun"
date: "2022-10-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tm)

data("AssociatedPress", package = "topicmodels")
AssociatedPress
```

```{r}
terms <- Terms(AssociatedPress)
head(terms)
```

```{r}
library(dplyr)
library(tidytext)

ap_td <- tidy(AssociatedPress)
ap_td
```

```{r}
ap_sentiments <- ap_td %>%
  inner_join(get_sentiments("bing"), by = c(term = "word"))

ap_sentiments
```

```{r}
library(ggplot2)

ap_sentiments %>%
  count(sentiment, term, wt = count) %>%
  ungroup() %>%
  filter(n >= 200) %>%
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
  mutate(term = reorder(term, n)) %>%
  ggplot(aes(n, term, fill = sentiment)) +
  geom_col() +
  labs(x = "Contribution to sentiment", y = NULL)
```

```{r}
data("data_corpus_inaugural", package = "quanteda")
inaug_dfm <- data_corpus_inaugural %>%
  quanteda::tokens() %>%
  quanteda::dfm(verbose = FALSE)
inaug_dfm
```

```{r}
inaug_td <- tidy(inaug_dfm)
inaug_td
```

```{r}
inaug_tf_idf <- inaug_td %>%
  bind_tf_idf(term, document, count) %>%
  arrange(desc(tf_idf))

inaug_tf_idf
```
```{r}
library(tidyr)

year_term_counts <- inaug_td %>%
  extract(document, "year", "(\\d+)", convert = TRUE) %>%
  complete(year, term, fill = list(count = 0)) %>%
  group_by(year) %>%
  mutate(year_total = sum(count))
```

```{r}
year_term_counts %>%
  filter(term %in% c("god", "america", "foreign", "union", "constitution", "freedom")) %>%
  ggplot(aes(year, count / year_total)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ term, scales = "free_y") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(y = "% frequency of word in inaugural address")
```
```{r}
ap_td %>%
  cast_dtm(document, term, count)
```

```{r}
library(Matrix)

# cast into a Matrix object
m <- ap_td %>%
  cast_sparse(document, term, count)

class(m)
dim(m)
```

```{r}
library(janeaustenr)

austen_dtm <- austen_books() %>%
  unnest_tokens(word, text) %>%
  count(book, word) %>%
  cast_dtm(book, word, n)

austen_dtm
```

```{r}
data("acq")
acq

acq[[1]]

```
```{r}
acq_td <- tidy(acq)
acq_td
```

```{r}
acq_tokens <- acq_td %>%
  select(-places) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word")

# most common words
acq_tokens %>%
  count(word, sort = TRUE)

# tf-idf
acq_tokens %>%
  count(id, word) %>%
  bind_tf_idf(word, id, n) %>%
  arrange(desc(tf_idf))
```

```{r}
library(tm.plugin.webmining)
library(purrr)

company <- c("Microsoft", "Apple", "Google", "Amazon", "Facebook",
             "Twitter", "IBM", "Yahoo", "Netflix")
symbol  <- c("MSFT", "AAPL", "GOOG", "AMZN", "FB", 
             "TWTR", "IBM", "YHOO", "NFLX")

download_articles <- function(symbol) {
  WebCorpus(GoogleFinanceSource(paste0("NASDAQ:", symbol)))
}

stock_articles <- tibble(company = company,
                         symbol = symbol) %>%
  mutate(corpus = map(symbol, download_articles))
```
```{r}
stock_articles
#> # A tibble: 9 × 3
#>   company   symbol corpus    
#>   <chr>     <chr>  <list>    
#> 1 Microsoft MSFT   <WebCorps>
#> 2 Apple     AAPL   <WebCorps>
#> 3 Google    GOOG   <WebCorps>
#> 4 Amazon    AMZN   <WebCorps>
#> 5 Facebook  FB     <WebCorps>
#> 6 Twitter   TWTR   <WebCorps>
#> 7 IBM       IBM    <WebCorps>
#> 8 Yahoo     YHOO   <WebCorps>
#> 9 Netflix   NFLX   <WebCorps>
```

```{r}
stock_tokens <- stock_articles %>%
  mutate(corpus = map(corpus, tidy)) %>%
  unnest(cols = (corpus)) %>%
  unnest_tokens(word, text) %>%
  select(company, datetimestamp, word, id, heading)

stock_tokens
#> # A tibble: 105,057 × 5
#>    company   datetimestamp       word        id                          heading
#>    <chr>     <dttm>              <chr>       <chr>                       <chr>  
#>  1 Microsoft 2017-01-17 12:07:24 microsoft   tag:finance.google.com,clu… Micros…
#>  2 Microsoft 2017-01-17 12:07:24 corporation tag:finance.google.com,clu… Micros…
#>  3 Microsoft 2017-01-17 12:07:24 data        tag:finance.google.com,clu… Micros…
#>  4 Microsoft 2017-01-17 12:07:24 privacy     tag:finance.google.com,clu… Micros…
#>  5 Microsoft 2017-01-17 12:07:24 could       tag:finance.google.com,clu… Micros…
#>  6 Microsoft 2017-01-17 12:07:24 send        tag:finance.google.com,clu… Micros…
#>  7 Microsoft 2017-01-17 12:07:24 msft        tag:finance.google.com,clu… Micros…
#>  8 Microsoft 2017-01-17 12:07:24 stock       tag:finance.google.com,clu… Micros…
#>  9 Microsoft 2017-01-17 12:07:24 soaring     tag:finance.google.com,clu… Micros…
#> 10 Microsoft 2017-01-17 12:07:24 by          tag:finance.google.com,clu… Micros…
#> # … with 105,047 more rows
```

```{r}
library(stringr)

stock_tf_idf <- stock_tokens %>%
  count(company, word) %>%
  filter(!str_detect(word, "\\d+")) %>%
  bind_tf_idf(word, company, n) %>%
  arrange(-tf_idf)
```

```{r}
stock_tokens %>%
  anti_join(stop_words, by = "word") %>%
  count(word, id, sort = TRUE) %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(word) %>%
  summarize(contribution = sum(n * value)) %>%
  slice_max(abs(contribution), n = 12) %>%
  mutate(word = reorder(word, contribution)) %>%
  ggplot(aes(contribution, word)) +
  geom_col() +
  labs(x = "Frequency of word * AFINN value", y = NULL)
```

```{r}
stock_tokens %>%
  count(word) %>%
  inner_join(get_sentiments("loughran"), by = "word") %>%
  group_by(sentiment) %>%
  slice_max(n, n = 5, with_ties = FALSE) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  facet_wrap(~ sentiment, scales = "free") +
  labs(x = "Frequency of this word in the recent financial articles", y = NULL)
```

```{r}
stock_sentiment_count <- stock_tokens %>%
  inner_join(get_sentiments("loughran"), by = "word") %>%
  count(sentiment, company) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0)

stock_sentiment_count
```

```{r}
stock_sentiment_count %>%
  mutate(score = (positive - negative) / (positive + negative)) %>%
  mutate(company = reorder(company, score)) %>%
  ggplot(aes(score, company, fill = score > 0)) +
  geom_col(show.legend = FALSE) +
  labs(x = "Positivity score among 20 recent news articles", y = NULL)
```

